{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Inspect Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Define paths\n",
    "json_path = '/home/kosal/AI/Dynamic_K_RAG/Dataset/Computer_Science_Theory_QA.json'\n",
    "csv_path  = '/home/kosal/AI/Dynamic_K_RAG/Dataset/Computer_Science_Theory_QA.csv'\n",
    "\n",
    "# Load the JSON file\n",
    "with open(json_path, 'r', encoding='utf8') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# Convert to a DataFrame\n",
    "df = pd.DataFrame(data['intents'])\n",
    "\n",
    "# Save to CSV (overwrite if exists)\n",
    "df.to_csv(csv_path, index=False, encoding='utf8')\n",
    "\n",
    "# Read back the CSV \n",
    "df = pd.read_csv(csv_path, encoding='utf8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Cleaning and Convert to JSONL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total QA pairs written: 347\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "# Saft Covert from String to List\n",
    "def safe_eval_list(val):\n",
    "    if isinstance(val, list):\n",
    "        return val\n",
    "    try:\n",
    "        return ast.literal_eval(val)\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "df['patterns'] = df['patterns'].apply(safe_eval_list)\n",
    "df['responses'] = df['responses'].apply(safe_eval_list)\n",
    "\n",
    "# Now, regenerate your QA pairs as before:\n",
    "output_jsonl = \"/home/kosal/AI/Dynamic_K_RAG/Dataset/cs_qa.jsonl\"\n",
    "qa_pairs = 0\n",
    "\n",
    "with open(output_jsonl, \"w\", encoding=\"utf8\") as f:\n",
    "    for _, row in df.iterrows():\n",
    "        for pattern in row['patterns']:\n",
    "            answer = row['responses'][0] if row['responses'] else \"\"\n",
    "            obj = {\n",
    "                \"question\": pattern.strip(),\n",
    "                \"answer\": answer.strip(),\n",
    "                \"tag\": row['tag']\n",
    "            }\n",
    "            f.write(json.dumps(obj, ensure_ascii=False) + \"\\n\")\n",
    "            qa_pairs += 1\n",
    "\n",
    "print(f\"Total QA pairs written: {qa_pairs}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Into Train / Val / Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 277 samples saved to cs_qa_train.jsonl\n",
      "val: 35 samples saved to cs_qa_val.jsonl\n",
      "test: 35 samples saved to cs_qa_test.jsonl\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load all JSONL lines\n",
    "with open(output_jsonl, encoding=\"utf8\") as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "\n",
    "train, temp = train_test_split(data, test_size=0.2, random_state=42)\n",
    "val, test = train_test_split(temp, test_size=0.5, random_state=42)\n",
    "\n",
    "for name, split in zip([\"train\", \"val\", \"test\"], [train, val, test]):\n",
    "    out_file = f\"cs_qa_{name}.jsonl\"\n",
    "    with open(out_file, \"w\", encoding=\"utf8\") as f:\n",
    "        for rec in split:\n",
    "            f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
    "    print(f\"{name}: {len(split)} samples saved to {out_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Facts Corpus & Vector Index Construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Facts Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique facts: 163\n",
      "Saved facts to /home/kosal/AI/Dynamic_K_RAG/Dataset/facts.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "facts = set()\n",
    "with open(\"/home/kosal/AI/Dynamic_K_RAG/Dataset/cs_qa_train.jsonl\", encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        qa = json.loads(line)\n",
    "        facts.add(qa[\"answer\"].strip())\n",
    "\n",
    "facts = list(facts)\n",
    "print(f\"Total unique facts: {len(facts)}\")\n",
    "\n",
    "facts_path = \"/home/kosal/AI/Dynamic_K_RAG/Dataset/facts.jsonl\"\n",
    "with open(facts_path, \"w\", encoding=\"utf8\") as f:\n",
    "    for idx, fact in enumerate(facts):\n",
    "        f.write(json.dumps({\"fact_id\": idx, \"fact\": fact}, ensure_ascii=False) + \"\\n\")\n",
    "print(f\"Saved facts to {facts_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 3/3 [00:00<00:00, 15.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (163, 384)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "facts = []\n",
    "fact_ids = []\n",
    "with open(facts_path, encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        item = json.loads(line)\n",
    "        facts.append(item[\"fact\"])\n",
    "        fact_ids.append(item[\"fact_id\"])\n",
    "\n",
    "# Load embedding model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Compute embeddings (batch for speed)\n",
    "embeddings = model.encode(facts, batch_size=64, show_progress_bar=True)\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the FAISS Vector Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 163 facts.\n",
      "FAISS index saved.\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "\n",
    "dim = embeddings.shape[1]  \n",
    "index = faiss.IndexHNSWFlat(dim, 32)\n",
    "index.hnsw.efConstruction = 200\n",
    "index.add(np.array(embeddings).astype(\"float32\"))\n",
    "print(f\"Indexed {index.ntotal} facts.\")\n",
    "\n",
    "# Save index to disk for future use\n",
    "faiss.write_index(index, \"/home/kosal/AI/Dynamic_K_RAG/Dataset/facts_hnsw.index\")\n",
    "print(\"FAISS index saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fact ID map saved.\n"
     ]
    }
   ],
   "source": [
    "fact_id_map = {i: fact for i, fact in enumerate(facts)}\n",
    "import pickle\n",
    "with open(\"/home/kosal/AI/Dynamic_K_RAG/Dataset/fact_id_map.pkl\", \"wb\") as f:\n",
    "    pickle.dump(fact_id_map, f)\n",
    "print(\"Fact ID map saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Retrieval End-to-End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-1 retrieved facts for query:\n",
      "- Data abstraction is a technique used in computer programming to separate the implementation details of a data type from its interface, allowing the implementation to be changed without affecting the code that uses it. This is often achieved through the use of abstract data types (ADTs), which are defined by the operations they support rather than their specific implementation, or through the use of interfaces and classes in object-oriented programming languages. Data abstraction helps to reduce the complexity of software systems by allowing code to be written in a modular and flexible way and by hiding the underlying details of data types from the user.\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "\n",
    "k=1\n",
    "\n",
    "index = faiss.read_index(\"/home/kosal/AI/Dynamic_K_RAG/Dataset/facts_hnsw.index\")\n",
    "\n",
    "test_query = \"Explain data abstraction in computer science.\"\n",
    "\n",
    "q_vec = model.encode([test_query])\n",
    "\n",
    "D, I = index.search(np.array(q_vec).astype(\"float32\"), k)\n",
    "\n",
    "import pickle\n",
    "with open(\"/home/kosal/AI/Dynamic_K_RAG/Dataset/fact_id_map.pkl\", \"rb\") as f:\n",
    "    fact_id_map = pickle.load(f)\n",
    "\n",
    "print(f\"Top-{k} retrieved facts for query:\")\n",
    "for idx in I[0]:\n",
    "    print(\"-\", fact_id_map[idx])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label Creation for Dynamic Top-K\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import faiss\n",
    "import pickle\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "qa_path = \"/home/kosal/AI/Dynamic_K_RAG/Dataset/cs_qa_train.jsonl\"\n",
    "index_path = \"/home/kosal/AI/Dynamic_K_RAG/Dataset/facts_hnsw.index\"\n",
    "fact_map_path = \"/home/kosal/AI/Dynamic_K_RAG/Dataset/fact_id_map.pkl\"\n",
    "\n",
    "with open(qa_path, encoding=\"utf8\") as f:\n",
    "    qa_data = [json.loads(line) for line in f]\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "index = faiss.read_index(index_path)\n",
    "with open(fact_map_path, \"rb\") as f:\n",
    "    fact_id_map = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exact Match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 277 QA examples.\n",
      "Saved label data to /home/kosal/AI/Dynamic_K_RAG/Dataset/dynamic_k_labels.jsonl\n"
     ]
    }
   ],
   "source": [
    "def exact_match(pred, gold):\n",
    "    \"\"\"Simple, case-insensitive, punctuation-stripped match.\"\"\"\n",
    "    import string\n",
    "    def normalize(s):\n",
    "        return ''.join(c.lower() for c in s if c not in string.punctuation).strip()\n",
    "    return normalize(pred) == normalize(gold)\n",
    "\n",
    "# Dummy Answer \n",
    "def generate_answer(context, question):\n",
    "    # TODO: Replace with your real LLM generation code!\n",
    "    # For now, just return the context or gold answer for debugging.\n",
    "    return context\n",
    "\n",
    "\n",
    "# Main Loop to find top k\n",
    "max_K = 10\n",
    "labels = []\n",
    "\n",
    "for ex in qa_data:\n",
    "    question = ex[\"question\"]\n",
    "    gold_answer = ex[\"answer\"]\n",
    "\n",
    "    # Embed the question\n",
    "    q_vec = model.encode([question])\n",
    "\n",
    "    found_k = max_K\n",
    "    for k in range(1, max_K+1):\n",
    "        D, I = index.search(np.array(q_vec).astype(\"float32\"), k)\n",
    "        context = \"\\n\".join([fact_id_map[idx] for idx in I[0][:k]])\n",
    "        candidate = generate_answer(context, question)\n",
    "        if exact_match(candidate, gold_answer):\n",
    "            found_k = k\n",
    "            break\n",
    "\n",
    "    labels.append({\n",
    "        \"question\": question,\n",
    "        \"question_embedding\": q_vec[0].tolist(),\n",
    "        \"gold_answer\": gold_answer,\n",
    "        \"best_k\": found_k\n",
    "    })\n",
    "\n",
    "print(f\"Processed {len(labels)} QA examples.\")\n",
    "\n",
    "labels_path = \"/home/kosal/AI/Dynamic_K_RAG/Dataset/dynamic_k_labels.jsonl\"\n",
    "with open(labels_path, \"w\", encoding=\"utf8\") as f:\n",
    "    for record in labels:\n",
    "        f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "print(f\"Saved label data to {labels_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dynamic_rag_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
